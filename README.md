# üéµ Proyecto M√≥dulo 2 ‚Äì MusicStream

**An√°lisis de Popularidad de Canciones en la Era Digital ‚Äì Proyecto M√≥dulo 2**

Proyecto de an√°lisis de datos musicales desarrollado por el Equipo 2 formado por **Camila L√≥pez, Arantxa Barea, Mar√≠a Granero y Lorena N√∫√±ez**.  
El objetivo es estudiar la evoluci√≥n de la popularidad de diferentes g√©neros, artistas, colaboraciones y tendencias globales utilizando datos de **Spotify** y **Last.fm** entre 2020 y 2024.

---

## üë• Equipo y Roles

| Miembro | Rol | Tareas principales |
|------|-----|------------------|
| Camila L√≥pez | Scrum Master / Data Analyst | Organizaci√≥n, tablero Kanban, definici√≥n de milestones, API Last.fm, extracci√≥n y limpieza de datos, desarrollo de queries SQL y revisi√≥n |
| Mar√≠a Granero | Data Analyst | API Spotify, extracci√≥n de datos, integraci√≥n y validaci√≥n de datasets, creaci√≥n y carga de la base de datos, desarrollo de queries SQL y revisi√≥n |
| Arantxa Barea | Data Analyst | API Spotify, extracci√≥n de datos, integraci√≥n y validaci√≥n de datasets creaci√≥n y carga de la base de datos, desarrollo de queries SQL y revisi√≥n |
| Lorena N√∫√±ez | Data Analyst | API Last.fm, extracci√≥n de datos, apoyo en limpieza y desarrollo de queries SQL y revisi√≥n |

---

## üéØ Objetivo del proyecto

Analizar la evoluci√≥n de la m√∫sica entre 2020 y 2024, centr√°ndose en los g√©neros **pop, latin, indie y hip-hop**.

### Objetivos espec√≠ficos
- Analizar la **popularidad media de cada g√©nero** a lo largo del tiempo  
- Identificar **artistas dominantes por g√©nero y a√±o**  
- Estudiar **colaboraciones e hibridaci√≥n entre g√©neros**  
- Explorar **tendencias globales** mediante tags, playcounts y oyentes  

---

## üîÑ Flujo general del proyecto

1. Extracci√≥n de datos desde las APIs de **Spotify** y **Last.fm** mediante Python.  
2. Limpieza, normalizaci√≥n y cruce de datos para crear datasets coherentes.  
3. Exportaci√≥n de los datos a **CSV**.  
4. Volcado de los datasets en **MySQL Workbench** utilizando **SQLAlchemy**.  
5. An√°lisis de los datos mediante queries SQL.  
6. Obtenci√≥n de insights sobre popularidad, tendencias y colaboraciones.  

---

## üß† Tecnolog√≠as y contenidos aplicados

### Python
- Consumo de APIs con `requests`
- Manejo de respuestas en formato JSON
- Manipulaci√≥n de datos con **pandas**
- Control de errores con `try/except`
- Funciones personalizadas para parsing y limpieza
- Exportaci√≥n de datos a CSV

### Bases de datos
- Dise√±o y carga de datos en **MySQL**
- Queries SQL para an√°lisis exploratorio
- Integraci√≥n Python‚ÄìMySQL mediante **SQLAlchemy**

---

## üìí Organizaci√≥n del c√≥digo

El proyecto se estructura en **dos notebooks principales y scripts SQL**:

- **Notebook 1 ‚Äì Extracci√≥n y limpieza de datos**  
  Incluye:
  - Llamadas a las APIs  
  - Procesamiento y limpieza de datos  
  - Normalizaci√≥n y matching entre fuentes  
  - Exportaci√≥n de datasets finales a CSV  

- **Notebook 2 ‚Äì Carga en MySQL y an√°lisis SQL**  
  Incluye:
  - Lectura de los CSV generados  
  - Conexi√≥n con MySQL mediante SQLAlchemy  
  - Volcado de los datos a la base de datos  
  - Ejecuci√≥n de queries y an√°lisis  

- **SQL Scripts ‚Äì Esquema y queries**  
  Incluye:
  - `schema.sql`: creaci√≥n completa de la base de datos y tablas
  - `queries.sql`: todas las queries utilizadas para an√°lisis y extracci√≥n de insights

---

## ‚ñ∂Ô∏è C√≥mo ejecutar el proyecto

### 1. Requisitos
- Python 3.9+
- MySQL Workbench
- Librer√≠as principales:
  - `pandas`
  - `requests`
  - `spotipy`
  - `sqlalchemy`
  - `pymysql`

---

### 2. Seguridad de credenciales (MySQL)

Para evitar exponer credenciales en un repositorio p√∫blico, la conexi√≥n a MySQL se realiza mediante **variables**.

En el notebook de carga a MySQL se definen variables para:
- Usuario de MySQL  
- Contrase√±a de MySQL  
- Host de conexi√≥n  

Cada persona puede configurar sus propios valores localmente sin que queden expuestos en el repositorio.

---

### 3. Ejecuci√≥n
1. Descargar los **CSV** ya generados.  
2. Ejecutar el **Notebook de carga a MySQL**, configurando previamente las variables de conexi√≥n.  
3. Realizar el an√°lisis mediante queries SQL en MySQL Workbench o desde Python.  

---

## üß™ Pruebas y control de errores

| Escenario | Manejo |
|---------|--------|
| Track no encontrado en Last.fm | Se captura el error y el proceso contin√∫a |
| Track sin tags | Se devuelve una lista vac√≠a |
| Diferentes formatos de URL | Se parsean correctamente |
| Inconsistencias entre fuentes | Normalizaci√≥n de nombres |
| Gran volumen de datos | Guardado parcial y control de progreso |

---

## üöÄ Posibles mejoras futuras

- Paralelizaci√≥n de llamadas a APIs para reducir tiempos de extracci√≥n  
- Inclusi√≥n de m√°s g√©neros y subg√©neros  
- An√°lisis de tendencias emergentes  
- Automatizaci√≥n completa del pipeline de datos  
- Ampliaci√≥n de visualizaciones interactivas en Tableau  

---

## üé§ Presentaci√≥n del proyecto

La presentaci√≥n incluye:
- Contexto y objetivos del proyecto  
- Flujo completo de extracci√≥n y limpieza de datos  
- Ejemplo de carga y query en MySQL  
- Visualizaciones y principales insights obtenidos  

---

## üìÑ Licencia

Proyecto acad√©mico desarrollado en el marco del bootcamp de **Adalab**.  
Uso educativo.

**Autores:**  
Camila L√≥pez ¬∑ Arantxa Barea ¬∑ Mar√≠a Granero ¬∑ Lorena N√∫√±ez  
