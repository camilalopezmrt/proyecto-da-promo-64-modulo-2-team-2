# üéµ Proyecto M√≥dulo 2 ‚Äì MusicStream

**An√°lisis de Popularidad de Canciones en la Era Digital ‚Äì Proyecto M√≥dulo 2**

Proyecto de an√°lisis de datos musicales desarrollado por el Equipo 2 formado por **Camila L√≥pez, Arantxa Barea, Mar√≠a Granero y Lorena N√∫√±ez**.  
El objetivo es estudiar la evoluci√≥n de la popularidad de diferentes g√©neros, artistas, colaboraciones y tendencias globales utilizando datos de **Spotify** y **Last.fm** entre 2020 y 2024.

---

## üë• Equipo y Roles

| Miembro | Rol | Tareas principales |
|------|-----|------------------|
| Camila L√≥pez | Scrum Master / Data Analyst | Organizaci√≥n, tablero Kanban, definici√≥n de milestones, API Last.fm, extracci√≥n y limpieza de datos, desarrollo de queries SQL y revisi√≥n |
| Mar√≠a Granero | Data Analyst | API Spotify, extracci√≥n de datos, integraci√≥n y validaci√≥n de datasets, creaci√≥n y carga de la base de datos, desarrollo de queries SQL y revisi√≥n |
| Arantxa Barea | Data Analyst | API Spotify, extracci√≥n de datos, integraci√≥n y validaci√≥n de datasets, creaci√≥n y carga de la base de datos, desarrollo de queries SQL y revisi√≥n |
| Lorena N√∫√±ez | Data Analyst | API Last.fm, extracci√≥n de datos, apoyo en limpieza y desarrollo de queries SQL y revisi√≥n |

---

## üéØ Objetivo del proyecto

Analizar la evoluci√≥n de la m√∫sica entre 2020 y 2024, centr√°ndose en los g√©neros **pop, latin, indie y hip-hop**.

### Objetivos espec√≠ficos
- Analizar la **popularidad media de cada g√©nero** a lo largo del tiempo  
- Identificar **artistas dominantes por g√©nero y a√±o**  
- Estudiar **colaboraciones e hibridaci√≥n entre g√©neros**  
- Explorar **tendencias globales** mediante tags, playcounts y oyentes  

---

## üîÑ Flujo general del proyecto

1. Extracci√≥n de datos desde las APIs de **Spotify** y **Last.fm** mediante Python.  
2. Limpieza, normalizaci√≥n y cruce de datos para crear datasets coherentes.  
3. Exportaci√≥n de los datos a **CSV**.  
4. Volcado de los datasets en **MySQL Workbench** utilizando **SQLAlchemy**.  
5. An√°lisis de los datos mediante queries SQL.  
6. Obtenci√≥n de insights sobre popularidad, tendencias y colaboraciones.  

---

## üß† Tecnolog√≠as y contenidos aplicados

### Python
- Consumo de APIs con `requests`
- Manejo de respuestas en formato JSON
- Manipulaci√≥n de datos con **pandas**
- Control de errores con `try/except`
- Funciones personalizadas para parsing y limpieza
- Exportaci√≥n de datos a CSV

### Bases de datos
- Dise√±o y carga de datos en **MySQL**
- Queries SQL para an√°lisis exploratorio
- Integraci√≥n Python‚ÄìMySQL mediante **SQLAlchemy**

---

## üìí Organizaci√≥n del c√≥digo

El proyecto se estructura en **dos notebooks principales y scripts SQL**:

- **Notebook 1 ‚Äì Extracci√≥n y limpieza de datos**  
  Incluye:
  - Llamadas a las APIs  
  - Procesamiento y limpieza de datos  
  - Normalizaci√≥n y matching entre fuentes  
  - Exportaci√≥n de datasets finales a CSV  

- **Notebook 2 ‚Äì Carga en MySQL y an√°lisis SQL**  
  Incluye:
  - Lectura de los CSV generados  
  - Conexi√≥n con MySQL mediante SQLAlchemy  
  - Volcado de los datos a la base de datos    

- **SQL Scripts ‚Äì Esquema y queries**  
  Incluye:
  - `Schema_RhythmIQ.sql`: creaci√≥n completa de la base de datos y tablas
  - `Script_queries_RhythmIQ.sql`: todas las queries utilizadas para an√°lisis y extracci√≥n de insights

---

## üóÇÔ∏è Estructura del repositorio

```text
proyecto-da-promo-64-modulo-2-team-2/   ‚Üê ra√≠z del repo
‚îú‚îÄ README.md
‚îú‚îÄ .gitignore
‚îú‚îÄ .env.example
‚îî‚îÄ docs_equipo/
   ‚îú‚îÄ Documentos_BBDD_queries/
   ‚îÇ  ‚îú‚îÄ Exportaci√≥n_resultados/
   ‚îÇ  ‚îú‚îÄ Diagrama_entidad_relaci√≥n_(DER).mwb
   ‚îÇ  ‚îú‚îÄ Script_queries_RhythmIQ.sql
   ‚îÇ  ‚îî‚îÄ Schema_RhythmIQ.sql
   ‚îî‚îÄ Documentos_extracci√≥n_datos/
      ‚îú‚îÄ dataset_spotify_tracks.csv
      ‚îú‚îÄ dataset_unificado.csv
      ‚îú‚îÄ df_lastfm.csv
      ‚îú‚îÄ maestro_artistas.csv
      ‚îú‚îÄ Fase1_Extracci√≥n_datos.ipynb
      ‚îî‚îÄ Fase2_Manipulaci√≥n_carga_datos.ipynb
```

---

## ‚ñ∂Ô∏è Pasos para configurar

### 1. Requisitos
- Python 3.9+
- MySQL Workbench
- Librer√≠as principales:
  - `pandas`
  - `requests`
  - `spotipy`
  - `sqlalchemy`
  - `pymysql`
  - `python-dotenv`  

---

### 2. Configuraci√≥n de variables de entorno (APIs y seguridad)

Para evitar exponer credenciales en un repositorio p√∫blico, las claves de las APIs no se incluyen en el repo. En su lugar, se utiliza un archivo de variables de entorno `.env` local.

### Archivo de ejemplo `.env.example`
```bash
# -----------------------------------------------------------------------------------------------------------------------
# ARCHIVO DE EJEMPLO DE VARIABLES DE ENTORNO
# -----------------------------------------------------------------------------------------------------------------------
# Copiar este archivo a .env y rellenar con tus propias claves de API.
# -----------------------------------------------------------------------------------------------------------------------

# Clave de API de Spotify
spotipy_api_key=TU_API_KEY

# Client Secret de Spotify
spotipy_client_secret=TU_CLIENT_SECRET

# Clave de API de Last.fm
lastfm_api_key=TU_LASTFM_KEY
```

### Pasos para configurar

1. Copiar `.env.example` a `.env` en la ra√≠z del proyecto:
```bash
   # Linux / Mac
   cp .env.example .env
   
   # Windows
   copy .env.example .env
```

2. Abrir `.env` y rellenar con tus propias claves de API. Ejemplo:
```
   spotipy_api_key=abcd1234
   spotipy_client_secret=efgh5678
   lastfm_api_key=ijkl9012
```

* Ejecutar los notebooks normalmente; el c√≥digo cargar√° las variables con `python-dotenv` y `os.getenv()`.

‚ö†Ô∏è**Cada persona debe crear su propio `.env` con sus credenciales. El archivo `.env` no se sube al repositorio, solo `.env.example`.**

---

### 3. Seguridad de credenciales (MySQL)

Para evitar exponer credenciales en un repositorio p√∫blico, la conexi√≥n a MySQL se realiza mediante variables locales.
```python
# Ejemplo de configuraci√≥n de variables locales para MySQL
mysql_user = "tu_usuario"
mysql_password = "tu_contrase√±a"
mysql_host = "localhost"
```

Cada persona puede configurar sus propios valores localmente sin que queden expuestos en el repositorio.

## 4. Ejecuci√≥n

1. Descargar los CSV ya generados (dataset_unificado.csv y maestro_artistas.csv)
2. Configurar .env con las claves de API propias
3. Ejecutar Notebook de extracci√≥n y limpieza
4. Ejecutar Notebook de carga a MySQL
5. Analizar los datos ejecutando las queries mediante el Script_queries_RhythmIQ.sql

---

### 4. Ejecuci√≥n

```bash
# 1. Descargar los CSV ya generados (dataset_unificado.csv y maestro_artistas.csv)
# 2. Configurar .env con las claves de API propias
# 3. Ejecutar Notebook de extracci√≥n y limpieza
# 4. Ejecutar Notebook de carga a MySQL
# 5. Analizar los datos ejecutando las queries mediante el Script_queries_RhythmIQ.sql

```

---

## üß™ Pruebas y control de errores

| Escenario | Manejo |
|---------|--------|
| Track no encontrado en Last.fm | Se captura el error y el proceso contin√∫a |
| Track sin tags | Se devuelve una lista vac√≠a |
| Diferentes formatos de URL | Se parsean correctamente |
| Inconsistencias entre fuentes | Normalizaci√≥n de nombres |
| Gran volumen de datos | Guardado parcial y control de progreso |

---

## üöÄ Posibles mejoras futuras

- Paralelizaci√≥n de llamadas a APIs para reducir tiempos de extracci√≥n  
- Inclusi√≥n de m√°s g√©neros y subg√©neros  
- An√°lisis de tendencias emergentes  
- Automatizaci√≥n completa del pipeline de datos  
- Ampliaci√≥n de visualizaciones interactivas en Tableau  

---

## üé§ Presentaci√≥n del proyecto

La presentaci√≥n incluye:
- Contexto y objetivos del proyecto  
- Flujo completo de extracci√≥n y limpieza de datos  
- Ejemplo de carga y query en MySQL  
- Visualizaciones y principales insights obtenidos  

---

## üìÑ Licencia

Proyecto acad√©mico desarrollado en el marco del bootcamp de **Adalab**.  
Uso educativo.

**Autores:**  
Camila L√≥pez ¬∑ Arantxa Barea ¬∑ Mar√≠a Granero ¬∑ Lorena N√∫√±ez

