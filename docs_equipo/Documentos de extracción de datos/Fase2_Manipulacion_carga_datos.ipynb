{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb89c8a0",
   "metadata": {},
   "source": [
    "#### **Fase 2: Procesamiento, Normalización y Carga (ETL)**\n",
    "\n",
    "**Objetivo:** Transformar el dataset unificado (`dataset_unificado.csv`) en una estructura relacional que cumpla con la **3NF** para su posterior volcado en una base de datos SQL utilizando **SQLAlchemy**.\n",
    "\n",
    "---\n",
    "\n",
    "El proceso seguirá estos pasos:\n",
    "\n",
    "1. **Lectura y Limpieza:**\n",
    "    * Carga de los datos integrados de Spotify y Last.fm.\n",
    "    * Tratamiento y estandarización final de tipos de datos.\n",
    "\n",
    "2. **Identificación de Entidades:**\n",
    "    * Separación del dataframe maestro en entidades independientes y únicas: **Álbumes, Artistas, Tracks, Géneros y Tags**.\n",
    "\n",
    "3. **Gestión de Relaciones N:M (Muchos a Muchos):**\n",
    "    * Construcción de las tablas intermedias para normalizar esas relaciones.\n",
    "\n",
    "4. **Mapeo de IDs (ID Management):**\n",
    "    * Carga secuencial en SQL respetando la jerarquía de dependencias.\n",
    "    * Recuperación de IDs autoincrementales generados por la BD para vincular las tablas mediante *Foreign Keys*.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5838bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos pandas para la lectura y manipulacion de la información:\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Cargamos el dataset unificado y el maestro de artistas generados en la fase 1 para iniciar la fase de transformación:\n",
    "df_unificado = pd.read_csv('dataset_unificado.csv')\n",
    "df_maestro_artistas = pd.read_csv('maestro_artistas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333b204",
   "metadata": {},
   "source": [
    "##### **1. Creación de tablas principales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886dd713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ENTIDAD: ALBUM ---\n",
    "\n",
    "# Extraemos álbumes únicos basándonos en el ID de Spotify para evitar duplicidad de títulos.\n",
    "df_album = df_unificado[['album_id', 'album_name', 'album_type', 'total_tracks', 'album_release_date', 'label']].drop_duplicates(subset=['album_id']).copy()\n",
    "df_album.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088141ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos registros nulos en 'album_name' para cumplir con la restricción NOT NULL de la base de datos.\n",
    "df_album2 = df_album.dropna(subset=['album_name'])\n",
    "df_album2.drop(columns=['album_id'], inplace=True)\n",
    "df_album2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ENTIDAD: ARTIST ---\n",
    "\n",
    "# Consolidamos la información del artista principal y colaboradores.\n",
    "# Renombramos columnas para asegurar la consistencia durante el cruce de datos (merge).\n",
    "df_nombres_ids = df_unificado[['artist', 'artistid']].drop_duplicates(subset=['artistid'])\n",
    "df_nombres_ids.rename(columns={'artist': 'artist_name', 'artistid': 'artist_id'}, inplace=True)\n",
    "\n",
    "# Unimos la información de ambos archivos\n",
    "df_artist = pd.merge(\n",
    "    df_nombres_ids, \n",
    "    df_maestro_artistas, \n",
    "    on='artist_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Selección de los atributos de la tabla artist\n",
    "df_artist = df_artist[['artist_name', 'artist_popularity', 'artist_followers']]\n",
    "df_artist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6f8eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ENTIDAD: GENRE ---\n",
    "\n",
    "# Aplicamos normalización (1NF): 'atomizamos' las listas de géneros para que cada registro sea único.\n",
    "# Esto convierte strings separados por comas en filas independientes y ordenadas.\n",
    "generos_unicos = df_maestro_artistas['artist_genres'].str.split(',').explode().str.strip().dropna().unique()\n",
    "\n",
    "# Creamos el DataFrame ordenado alfabéticamente\n",
    "df_genre = pd.DataFrame({'genre_name': sorted(list(generos_unicos))})\n",
    "df_genre.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ENTIDAD: TAG ---\n",
    "\n",
    "# Aplicamos normalización (1NF): 'atomizamos' las listas de tags para que cada registro sea único.\n",
    "# Como aparecen tags extraños, limpiamos y evitamos tags imprecisos que no aporten valor.\n",
    "tags_unicos = df_unificado['tags'].str.split(',').explode().str.strip().dropna().unique()\n",
    "tags_filtrados = [t for t in tags_unicos if len(str(t)) > 2 and not str(t).isdigit()]\n",
    "\n",
    "# Creamos el DataFrame ordenado alfabéticamente\n",
    "df_tags = pd.DataFrame({'tags': sorted(list(tags_filtrados))})\n",
    "df_tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87489b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ENTIDAD: TRACK ---\n",
    "\n",
    "# Seleccionamos los atributos. Mantenemos 'album_name' temporalmente para el mapeo de llaves foráneas.\n",
    "df_tracks = df_unificado[[\n",
    "    'track', 'track_release_date', 'track_popularity', \n",
    "    'track_year', 'collaboration', 'genre_extracted', \n",
    "    'listeners', 'playcount', 'artist', 'album_id', 'album_name'\n",
    "]].copy()\n",
    "\n",
    "df_tracks.rename(columns={'track': 'track_name'}, inplace=True)\n",
    "\n",
    "df_tracks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400876bc",
   "metadata": {},
   "source": [
    "##### **2. Volcado a SQL y gestión de llaves foráneas (FK)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce11a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "from sqlalchemy import create_engine,FLOAT, VARCHAR, INTEGER, DATE, SmallInteger\n",
    "from sqlalchemy.sql.sqltypes import String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a271d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos la conexión con la BD\n",
    "mysql_user = input(\"Introduce tu usuario de MySQL: \")\n",
    "mysql_password = input(\"Introduce tu contraseña de MySQL: \")\n",
    "mysql_host = input(\"Introduce tu host de MySQL: \")\n",
    "\n",
    "try:\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://{mysql_user}:{mysql_password}@{mysql_host}/rhythmiq\")\n",
    "    print(\"Conexión establecida con éxito\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volcado de ALBUM: Es necesario cargar esta tabla primero para generar los IDs que usará la tabla Track\n",
    "try:\n",
    "    df_album2.to_sql('album', engine, if_exists='append', index=False) \n",
    "    print(\"Datos insertados correctamente.\")\n",
    "    print(f\"Se han insertado {len(df_album2)} registros.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddfb266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de llaves foráneas:\n",
    "# Leemos los IDs generados automáticamente por SQL para vincular correctamente cada canción con su álbum:\n",
    "\n",
    "df_album_db = pd.read_sql(\"SELECT album_id, album_name FROM album\", engine)\n",
    "df_album_db_clean = df_album_db.drop_duplicates(subset=['album_name'])\n",
    "\n",
    "# Cruzamos la tabla de canciones con la de álbumes para obtener el ID numérico (Foreign Key)\n",
    "df_track2 = pd.merge(df_tracks, df_album_db_clean, on='album_name', how='left')\n",
    "\n",
    "# Limpieza final de la tabla TRACK: Eliminamos columnas redundantes y renombramos la FK\n",
    "df_track2.rename(columns={'album_id_y': 'album_id'}, inplace=True)\n",
    "df_track_final = df_track2.drop(columns=['artist', 'album_id_x', 'album_name'])\n",
    "df_track_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feb981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volcado de ARTIST\n",
    "try:\n",
    "    df_artist.to_sql('artist', engine, if_exists='append', index=False) \n",
    "    print(\"Datos insertados correctamente.\")\n",
    "    print(f\"Se han insertado {len(df_artist)} registros.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volcado de GENRE\n",
    "try:\n",
    "    df_genre.to_sql('genre', engine, if_exists='append', index=False) \n",
    "    print(\"Datos insertados correctamente.\")\n",
    "    print(f\"Se han insertado {len(df_genre)} registros.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b89a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volcado de TAG\n",
    "try:\n",
    "    df_tags.to_sql('tag', engine, if_exists='append', index=False) \n",
    "    print(\"Datos insertados correctamente.\")\n",
    "    print(f\"Se han insertado {len(df_tags)} registros.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b86fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volcado de TRACK\n",
    "try:\n",
    "    df_track_final.to_sql('track', engine, if_exists='append', index=False) \n",
    "    print(\"Datos insertados correctamente.\")\n",
    "    print(f\"Se han insertado {len(df_track_final)} registros.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29d92e9",
   "metadata": {},
   "source": [
    "##### **3. Generación de Tablas Intermedias y Relaciones (N:M)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7606b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de llaves foráneas de todas las tablas creadas:\n",
    "# Leemos los IDs generados automáticamente por SQL para vincular correctamente cada tabla:\n",
    "\n",
    "df_artist_db = pd.read_sql(\"SELECT artist_id, artist_name FROM artist\", engine)\n",
    "df_genre_db = pd.read_sql(\"SELECT genre_id, genre_name FROM genre\", engine)\n",
    "df_tag_db = pd.read_sql(\"SELECT tag_id, tags FROM tag\", engine)\n",
    "df_track_db = pd.read_sql(\"SELECT track_id, track_name FROM track\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6598df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TABLA INTERMEDIA: TRACK_ARTIST ---\n",
    "# Relaciona cada canción con todos sus artistas (principales y colaboradores).\n",
    "\n",
    "df_track_artist = (df_unificado[['track', 'artist', 'all_artists_names']]\n",
    "    .assign(all_artists_names=df_unificado['all_artists_names'].str.split(','))\n",
    "    .explode('all_artists_names')\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "df_track_artist['all_artists_names'] = df_track_artist['all_artists_names'].str.strip()\n",
    "\n",
    "df_track_artist['is_main_artist'] = (df_track_artist['all_artists_names'] == df_track_artist['artist']).astype(int)\n",
    "\n",
    "# Cruzamos con los IDs de SQL\n",
    "df_inter_track_artist = pd.merge(\n",
    "    df_track_artist, \n",
    "    df_track_db, \n",
    "    left_on='track', \n",
    "    right_on='track_name'\n",
    ")\n",
    "\n",
    "df_inter_track_artist = pd.merge(\n",
    "    df_inter_track_artist, \n",
    "    df_artist_db, \n",
    "    left_on='all_artists_names', \n",
    "    right_on='artist_name'\n",
    ")\n",
    "\n",
    "# Limpiamos y volcamos\n",
    "df_final_track_artist = (df_inter_track_artist[['track_id', 'artist_id', 'is_main_artist']].drop_duplicates(subset=['track_id', 'artist_id']))\n",
    "\n",
    "try:\n",
    "    df_final_track_artist.to_sql('track_artist', engine, if_exists='append', index=False)\n",
    "    print(\"Datos insertados correctamente.\")\n",
    "    print(f\"Se han insertado {len(df_final_track_artist)} registros.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4657693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TABLA INTERMEDIA: ARTIST_GENRE ---\n",
    "# Relaciona a los artistas con sus estilos musicales.\n",
    "\n",
    "mapa_nombres = df_unificado[['artistid', 'artist']].drop_duplicates()\n",
    "mapa_nombres.columns = ['artist_id', 'artist_name']\n",
    "\n",
    "df_art_gen = (df_maestro_artistas[['artist_id', 'artist_genres']]\n",
    "              .assign(artist_genres=df_maestro_artistas['artist_genres'].str.split(','))\n",
    "              .explode('artist_genres')\n",
    "              .dropna())\n",
    "df_art_gen['artist_genres'] = df_art_gen['artist_genres'].str.strip()\n",
    "\n",
    "df_art_gen = pd.merge(df_art_gen, mapa_nombres, on='artist_id')\n",
    "df_art_gen['artist_genres'] = df_art_gen['artist_genres'].str.strip()\n",
    "\n",
    "# Cruzamos con los IDs de SQL\n",
    "\n",
    "df_inter_art_gen = pd.merge(\n",
    "    df_art_gen, \n",
    "    df_artist_db, \n",
    "    on='artist_name'\n",
    ")\n",
    "\n",
    "df_inter_art_gen = pd.merge(\n",
    "    df_inter_art_gen, \n",
    "    df_genre_db, \n",
    "    left_on='artist_genres', \n",
    "    right_on='genre_name'\n",
    ")\n",
    "\n",
    "# Limpiamos y volcamos\n",
    "df_final_art_gen = df_inter_art_gen[['artist_id_y', 'genre_id']].drop_duplicates()\n",
    "df_final_art_gen.columns = ['artist_id', 'genre_id']\n",
    "\n",
    "try:\n",
    "    df_final_art_gen.to_sql('artist_genre', engine, if_exists='append', index=False)    \n",
    "    print(\"Datos insertados correctamente.\")\n",
    "    print(f\"Se han insertado {len(df_final_art_gen)} registros.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95f466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TABLA INTERMEDIA: TRACK_TAG ---\n",
    "# Relaciona cada canción con todos sus artistas (principales y colaboradores).\n",
    "\n",
    "df_track_tag = (df_unificado[['track', 'tags']]\n",
    "                .assign(tags=df_unificado['tags'].str.split(','))\n",
    "                .explode('tags')\n",
    "                .dropna())\n",
    "df_track_tag['tags'] = df_track_tag['tags'].str.strip()\n",
    "df_track_tag['track'] = df_track_tag['track'].str.strip()\n",
    "\n",
    "# Cruzamos con los IDs de SQL\n",
    "df_inter_track_tag = pd.merge(\n",
    "    df_track_tag, \n",
    "    df_track_db, \n",
    "    left_on='track', \n",
    "    right_on='track_name'\n",
    ")\n",
    "\n",
    "df_inter_track_tag = pd.merge(\n",
    "    df_inter_track_tag, \n",
    "    df_tag_db, \n",
    "    left_on='tags', \n",
    "    right_on='tags'\n",
    ")\n",
    "\n",
    "# Limpiamos y volcamos\n",
    "df_final_track_tag = df_inter_track_tag[['track_id', 'tag_id']].drop_duplicates()\n",
    "\n",
    "try:\n",
    "    df_final_track_tag.to_sql('track_tag', engine, if_exists='append', index=False)\n",
    "    print(\"Datos insertados correctamente.\")\n",
    "    print(f\"Se han insertado {len(df_final_track_tag)} registros.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
